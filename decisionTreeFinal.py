from sklearn.preprocessing import OneHotEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn import metrics
import numpy as np
from itertools import cycle
from sklearn.preprocessing import label_binarize
from sklearn.metrics import classification_report
import matplotlib.pyplot as plt


generalFeatureLocation = "F:\\Malware\\"
infoGainLocation = "C:\\Users\\Ben\\Documents\\GitHub\\DS4400-MalwareClassification\\"

count = 0
#Load data into system
trainX = list()
trainY = list()

featuresToAdd = list()
with open(generalFeatureLocation+"informationGainAbove0.6", "r") as reader:
	for line in reader:
		featuresToAdd.append(int(line))
print("Loaded feature list")

count = 0
with open(generalFeatureLocation+"trainFeatures", "r") as reader:
	for line in reader:
		if count%1000 == 999:
			print(count)

		count += 1
		splittedData = line.split(",")

		toAdd = list()
		for feature in featuresToAdd:
			toAdd.append(int(splittedData[feature]))
		trainX.append(toAdd)
		trainY.append(int(splittedData[-1]))

scaler = StandardScaler()
trainX = scaler.fit_transform(trainX)		
print("Loaded all training set")

testX = list()
testY = list()
count = 0
with open(generalFeatureLocation+"testFeatures", "r") as reader:
	for line in reader:
		if count%500 == 499:
			print(count)
			
		count += 1
		splittedData = line.split(",")

		toAdd = list()
		for feature in featuresToAdd:
			toAdd.append(int(splittedData[feature]))
		testX.append(toAdd)
		testY.append(int(splittedData[-1]))

testX = scaler.transform(testX)
		
print("Loaded all test set")


ranForestClas = RandomForestClassifier(n_estimators = 100)
ranForestClas.fit(trainX, trainY)			
y_pred = ranForestClas.predict(trainX)

accuracy = metrics.accuracy_score(trainY, y_pred)
f1Score = metrics.f1_score(trainY, y_pred, average="macro")
confMatrix = metrics.confusion_matrix(trainY, y_pred)
print("Decision Tree Training Set")
print("Accuracy: ", accuracy)
print("F1 Score: ", f1Score)
print(confMatrix)
print()


y_pred = ranForestClas.predict(testX)
accuracy = metrics.accuracy_score(testY, y_pred)
f1Score = metrics.f1_score(testY, y_pred, average="macro")
confMatrix = metrics.confusion_matrix(testY, y_pred)
print("Decision Tree Test Set")
print("Accuracy: ", accuracy)
print("F1 Score: ", f1Score)

print(classification_report(testY, y_pred))


print(confMatrix)
print()



lw = 2
predictions = ranForestClas.predict_proba(testX)


testY = label_binarize(testY, classes=range(1,10))

# Compute ROC curve and ROC area for each class
fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(9):
	fpr[i], tpr[i], _ = metrics.roc_curve(testY[:, i], predictions[:, i])
	roc_auc[i] = metrics.auc(fpr[i], tpr[i])

colors = cycle(['aqua', 'darkorange', 'cornflowerblue', "green", "red", "black", "yellow", "navy", "purple"])
for i, color in zip(range(9), colors):
    plt.plot(fpr[i], tpr[i], color=color, lw=lw,
             label='ROC curve of class {0} (area = {1:0.2f})'
             ''.format(i, roc_auc[i]))

plt.plot([0, 1], [0, 1], 'k--', lw=lw)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Some extension of Receiver operating characteristic to multi-class')
plt.legend(loc="lower right")
plt.show()